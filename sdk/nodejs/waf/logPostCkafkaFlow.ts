// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";
import * as utilities from "../utilities";

/**
 * Provides a resource to create a WAF log post ckafka flow
 *
 * ## Example Usage
 *
 * ### If vipType is 1
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as tencentcloud from "@tencentcloud_iac/pulumi";
 *
 * const example = new tencentcloud.waf.LogPostCkafkaFlow("example", {
 *     ckafkaRegion: "ap-guangzhou",
 *     ckafkaId: "ckafka-qzoeajkz",
 *     brokers: "ckafka-qzoeajkz.ap-guangzhou.ckafka.tencentcloudmq.com:50000",
 *     compression: "snappy",
 *     vipType: 1,
 *     logType: 2,
 *     topic: "tf-example",
 *     kafkaVersion: "2.8.1",
 *     saslEnable: 1,
 *     saslUser: "ckafka-qzoeajkz#root",
 *     saslPassword: "Password@123",
 *     writeConfig: {
 *         enableBody: 1,
 *         enableBot: 1,
 *         enableHeaders: 1,
 *     },
 * });
 * ```
 *
 * ### If vipType is 2
 *
 * ```typescript
 * import * as pulumi from "@pulumi/pulumi";
 * import * as tencentcloud from "@tencentcloud_iac/pulumi";
 *
 * const example = new tencentcloud.waf.LogPostCkafkaFlow("example", {
 *     ckafkaRegion: "ap-guangzhou",
 *     ckafkaId: "ckafka-k9m5vwar",
 *     brokers: "11.135.14.110:18737",
 *     compression: "snappy",
 *     vipType: 2,
 *     logType: 1,
 *     topic: "tf-example",
 *     kafkaVersion: "2.8.1",
 *     writeConfig: {
 *         enableBody: 0,
 *         enableBot: 1,
 *         enableHeaders: 0,
 *     },
 * });
 * ```
 *
 * ## Import
 *
 * WAF log post ckafka flow can be imported using the id, e.g.
 *
 * If log_type is 1
 *
 * ```sh
 * $ pulumi import tencentcloud:Waf/logPostCkafkaFlow:LogPostCkafkaFlow example 100536#1
 * ```
 *
 * If log_type is 2
 *
 * ```sh
 * $ pulumi import tencentcloud:Waf/logPostCkafkaFlow:LogPostCkafkaFlow example 100541#2
 * ```
 */
export class LogPostCkafkaFlow extends pulumi.CustomResource {
    /**
     * Get an existing LogPostCkafkaFlow resource's state with the given name, ID, and optional extra
     * properties used to qualify the lookup.
     *
     * @param name The _unique_ name of the resulting resource.
     * @param id The _unique_ provider ID of the resource to lookup.
     * @param state Any extra arguments used during the lookup.
     * @param opts Optional settings to control the behavior of the CustomResource.
     */
    public static get(name: string, id: pulumi.Input<pulumi.ID>, state?: LogPostCkafkaFlowState, opts?: pulumi.CustomResourceOptions): LogPostCkafkaFlow {
        return new LogPostCkafkaFlow(name, <any>state, { ...opts, id: id });
    }

    /** @internal */
    public static readonly __pulumiType = 'tencentcloud:Waf/logPostCkafkaFlow:LogPostCkafkaFlow';

    /**
     * Returns true if the given object is an instance of LogPostCkafkaFlow.  This is designed to work even
     * when multiple copies of the Pulumi SDK have been loaded into the same process.
     */
    public static isInstance(obj: any): obj is LogPostCkafkaFlow {
        if (obj === undefined || obj === null) {
            return false;
        }
        return obj['__pulumiType'] === LogPostCkafkaFlow.__pulumiType;
    }

    /**
     * The supporting environment is IP:PORT, The external network environment is domain:PORT.
     */
    declare public readonly brokers: pulumi.Output<string>;
    /**
     * CKafka ID.
     */
    declare public readonly ckafkaId: pulumi.Output<string>;
    /**
     * The region where CKafka is located for delivery.
     */
    declare public readonly ckafkaRegion: pulumi.Output<string>;
    /**
     * Default to none, supports snappy, gzip, and lz4 compression, recommended snappy.
     */
    declare public readonly compression: pulumi.Output<string>;
    /**
     * Unique ID for post cls flow.
     */
    declare public /*out*/ readonly flowId: pulumi.Output<number>;
    /**
     * Version number of Kafka cluster.
     */
    declare public readonly kafkaVersion: pulumi.Output<string>;
    /**
     * 1- Access log, 2- Attack log, the default is access log.
     */
    declare public readonly logType: pulumi.Output<number>;
    /**
     * Whether to enable SASL verification, default not enabled, 0-off, 1-on.
     */
    declare public readonly saslEnable: pulumi.Output<number>;
    /**
     * SASL password.
     */
    declare public readonly saslPassword: pulumi.Output<string | undefined>;
    /**
     * SASL username.
     */
    declare public readonly saslUser: pulumi.Output<string | undefined>;
    /**
     * Status 0- Off 1- On.
     */
    declare public /*out*/ readonly status: pulumi.Output<number>;
    /**
     * Theme name, default not to pass or pass empty string, default value is waf_post_access_log.
     */
    declare public readonly topic: pulumi.Output<string>;
    /**
     * 1. External network TGW, 2. Supporting environment, default is supporting environment.
     */
    declare public readonly vipType: pulumi.Output<number>;
    /**
     * Enable access to certain fields of the log and check if they have been delivered.
     */
    declare public readonly writeConfig: pulumi.Output<outputs.Waf.LogPostCkafkaFlowWriteConfig>;

    /**
     * Create a LogPostCkafkaFlow resource with the given unique name, arguments, and options.
     *
     * @param name The _unique_ name of the resource.
     * @param args The arguments to use to populate this resource's properties.
     * @param opts A bag of options that control this resource's behavior.
     */
    constructor(name: string, args: LogPostCkafkaFlowArgs, opts?: pulumi.CustomResourceOptions)
    constructor(name: string, argsOrState?: LogPostCkafkaFlowArgs | LogPostCkafkaFlowState, opts?: pulumi.CustomResourceOptions) {
        let resourceInputs: pulumi.Inputs = {};
        opts = opts || {};
        if (opts.id) {
            const state = argsOrState as LogPostCkafkaFlowState | undefined;
            resourceInputs["brokers"] = state?.brokers;
            resourceInputs["ckafkaId"] = state?.ckafkaId;
            resourceInputs["ckafkaRegion"] = state?.ckafkaRegion;
            resourceInputs["compression"] = state?.compression;
            resourceInputs["flowId"] = state?.flowId;
            resourceInputs["kafkaVersion"] = state?.kafkaVersion;
            resourceInputs["logType"] = state?.logType;
            resourceInputs["saslEnable"] = state?.saslEnable;
            resourceInputs["saslPassword"] = state?.saslPassword;
            resourceInputs["saslUser"] = state?.saslUser;
            resourceInputs["status"] = state?.status;
            resourceInputs["topic"] = state?.topic;
            resourceInputs["vipType"] = state?.vipType;
            resourceInputs["writeConfig"] = state?.writeConfig;
        } else {
            const args = argsOrState as LogPostCkafkaFlowArgs | undefined;
            if (args?.brokers === undefined && !opts.urn) {
                throw new Error("Missing required property 'brokers'");
            }
            if (args?.ckafkaId === undefined && !opts.urn) {
                throw new Error("Missing required property 'ckafkaId'");
            }
            if (args?.ckafkaRegion === undefined && !opts.urn) {
                throw new Error("Missing required property 'ckafkaRegion'");
            }
            if (args?.compression === undefined && !opts.urn) {
                throw new Error("Missing required property 'compression'");
            }
            if (args?.kafkaVersion === undefined && !opts.urn) {
                throw new Error("Missing required property 'kafkaVersion'");
            }
            if (args?.logType === undefined && !opts.urn) {
                throw new Error("Missing required property 'logType'");
            }
            if (args?.topic === undefined && !opts.urn) {
                throw new Error("Missing required property 'topic'");
            }
            if (args?.vipType === undefined && !opts.urn) {
                throw new Error("Missing required property 'vipType'");
            }
            resourceInputs["brokers"] = args?.brokers;
            resourceInputs["ckafkaId"] = args?.ckafkaId;
            resourceInputs["ckafkaRegion"] = args?.ckafkaRegion;
            resourceInputs["compression"] = args?.compression;
            resourceInputs["kafkaVersion"] = args?.kafkaVersion;
            resourceInputs["logType"] = args?.logType;
            resourceInputs["saslEnable"] = args?.saslEnable;
            resourceInputs["saslPassword"] = args?.saslPassword ? pulumi.secret(args.saslPassword) : undefined;
            resourceInputs["saslUser"] = args?.saslUser;
            resourceInputs["topic"] = args?.topic;
            resourceInputs["vipType"] = args?.vipType;
            resourceInputs["writeConfig"] = args?.writeConfig;
            resourceInputs["flowId"] = undefined /*out*/;
            resourceInputs["status"] = undefined /*out*/;
        }
        opts = pulumi.mergeOptions(utilities.resourceOptsDefaults(), opts);
        const secretOpts = { additionalSecretOutputs: ["saslPassword"] };
        opts = pulumi.mergeOptions(opts, secretOpts);
        super(LogPostCkafkaFlow.__pulumiType, name, resourceInputs, opts);
    }
}

/**
 * Input properties used for looking up and filtering LogPostCkafkaFlow resources.
 */
export interface LogPostCkafkaFlowState {
    /**
     * The supporting environment is IP:PORT, The external network environment is domain:PORT.
     */
    brokers?: pulumi.Input<string>;
    /**
     * CKafka ID.
     */
    ckafkaId?: pulumi.Input<string>;
    /**
     * The region where CKafka is located for delivery.
     */
    ckafkaRegion?: pulumi.Input<string>;
    /**
     * Default to none, supports snappy, gzip, and lz4 compression, recommended snappy.
     */
    compression?: pulumi.Input<string>;
    /**
     * Unique ID for post cls flow.
     */
    flowId?: pulumi.Input<number>;
    /**
     * Version number of Kafka cluster.
     */
    kafkaVersion?: pulumi.Input<string>;
    /**
     * 1- Access log, 2- Attack log, the default is access log.
     */
    logType?: pulumi.Input<number>;
    /**
     * Whether to enable SASL verification, default not enabled, 0-off, 1-on.
     */
    saslEnable?: pulumi.Input<number>;
    /**
     * SASL password.
     */
    saslPassword?: pulumi.Input<string>;
    /**
     * SASL username.
     */
    saslUser?: pulumi.Input<string>;
    /**
     * Status 0- Off 1- On.
     */
    status?: pulumi.Input<number>;
    /**
     * Theme name, default not to pass or pass empty string, default value is waf_post_access_log.
     */
    topic?: pulumi.Input<string>;
    /**
     * 1. External network TGW, 2. Supporting environment, default is supporting environment.
     */
    vipType?: pulumi.Input<number>;
    /**
     * Enable access to certain fields of the log and check if they have been delivered.
     */
    writeConfig?: pulumi.Input<inputs.Waf.LogPostCkafkaFlowWriteConfig>;
}

/**
 * The set of arguments for constructing a LogPostCkafkaFlow resource.
 */
export interface LogPostCkafkaFlowArgs {
    /**
     * The supporting environment is IP:PORT, The external network environment is domain:PORT.
     */
    brokers: pulumi.Input<string>;
    /**
     * CKafka ID.
     */
    ckafkaId: pulumi.Input<string>;
    /**
     * The region where CKafka is located for delivery.
     */
    ckafkaRegion: pulumi.Input<string>;
    /**
     * Default to none, supports snappy, gzip, and lz4 compression, recommended snappy.
     */
    compression: pulumi.Input<string>;
    /**
     * Version number of Kafka cluster.
     */
    kafkaVersion: pulumi.Input<string>;
    /**
     * 1- Access log, 2- Attack log, the default is access log.
     */
    logType: pulumi.Input<number>;
    /**
     * Whether to enable SASL verification, default not enabled, 0-off, 1-on.
     */
    saslEnable?: pulumi.Input<number>;
    /**
     * SASL password.
     */
    saslPassword?: pulumi.Input<string>;
    /**
     * SASL username.
     */
    saslUser?: pulumi.Input<string>;
    /**
     * Theme name, default not to pass or pass empty string, default value is waf_post_access_log.
     */
    topic: pulumi.Input<string>;
    /**
     * 1. External network TGW, 2. Supporting environment, default is supporting environment.
     */
    vipType: pulumi.Input<number>;
    /**
     * Enable access to certain fields of the log and check if they have been delivered.
     */
    writeConfig?: pulumi.Input<inputs.Waf.LogPostCkafkaFlowWriteConfig>;
}
