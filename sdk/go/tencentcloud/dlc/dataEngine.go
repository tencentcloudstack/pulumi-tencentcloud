// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package dlc

import (
	"context"
	"reflect"

	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Provides a resource to create a dlc dataEngine
//
// ## Example Usage
//
// ```go
// package main
//
// import (
//
//	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
//	"github.com/tencentcloudstack/pulumi-tencentcloud/sdk/go/tencentcloud/Dlc"
//
// )
//
//	func main() {
//		pulumi.Run(func(ctx *pulumi.Context) error {
//			_, err := Dlc.NewDataEngine(ctx, "dataEngine", &Dlc.DataEngineArgs{
//				AutoResume:           pulumi.Bool(false),
//				AutoSuspend:          pulumi.Bool(false),
//				CidrBlock:            pulumi.String("10.255.0.0/16"),
//				ClusterType:          pulumi.String("spark_cu"),
//				CrontabResumeSuspend: pulumi.Int(0),
//				DataEngineName:       pulumi.String("testSpark"),
//				DefaultDataEngine:    pulumi.Bool(false),
//				EngineExecType:       pulumi.String("BATCH"),
//				EngineType:           pulumi.String("spark"),
//				MaxClusters:          pulumi.Int(1),
//				Message:              pulumi.String("test spark1"),
//				MinClusters:          pulumi.Int(1),
//				Mode:                 pulumi.Int(1),
//				PayMode:              pulumi.Int(0),
//				Size:                 pulumi.Int(16),
//				TimeSpan:             pulumi.Int(1),
//				TimeUnit:             pulumi.String("h"),
//			})
//			if err != nil {
//				return err
//			}
//			return nil
//		})
//	}
//
// ```
//
// ## Import
//
// dlc data_engine can be imported using the id, e.g.
//
// ```sh
//
//	$ pulumi import tencentcloud:Dlc/dataEngine:DataEngine data_engine data_engine_id
//
// ```
type DataEngine struct {
	pulumi.CustomResourceState

	// Engine auto renew, only support 0: Default, 1: AutoRenewON, 2: AutoRenewOFF.
	AutoRenew pulumi.IntPtrOutput `pulumi:"autoRenew"`
	// Whether to automatically start the cluster, prepay not support.
	AutoResume pulumi.BoolOutput `pulumi:"autoResume"`
	// Whether to automatically suspend the cluster, prepay not support.
	AutoSuspend pulumi.BoolPtrOutput `pulumi:"autoSuspend"`
	// Cluster automatic suspension time, default 10 minutes.
	AutoSuspendTime pulumi.IntOutput `pulumi:"autoSuspendTime"`
	// Engine VPC network segment, just like 192.0.2.1/24.
	CidrBlock pulumi.StringPtrOutput `pulumi:"cidrBlock"`
	// Engine cluster type, only support: spark_cu/presto_cu.
	ClusterType pulumi.StringOutput `pulumi:"clusterType"`
	// Engine crontab resume or suspend strategy, only support: 0: Wait(default), 1: Kill.
	CrontabResumeSuspend pulumi.IntPtrOutput `pulumi:"crontabResumeSuspend"`
	// Engine auto suspend strategy, when AutoSuspend is true, CrontabResumeSuspend must stop.
	CrontabResumeSuspendStrategy DataEngineCrontabResumeSuspendStrategyOutput `pulumi:"crontabResumeSuspendStrategy"`
	// Cluster advanced configuration.
	DataEngineConfigPairs DataEngineDataEngineConfigPairArrayOutput `pulumi:"dataEngineConfigPairs"`
	// Engine name.
	DataEngineName pulumi.StringOutput `pulumi:"dataEngineName"`
	// Whether it is the default virtual cluster.
	DefaultDataEngine pulumi.BoolPtrOutput `pulumi:"defaultDataEngine"`
	// For spark Batch ExecType, yearly and monthly cluster elastic limit.
	ElasticLimit pulumi.IntPtrOutput `pulumi:"elasticLimit"`
	// For spark Batch ExecType, yearly and monthly cluster whether to enable elasticity.
	ElasticSwitch pulumi.BoolPtrOutput `pulumi:"elasticSwitch"`
	// Engine exec type, only support SQL(default) or BATCH.
	EngineExecType pulumi.StringPtrOutput `pulumi:"engineExecType"`
	// Engine type, only support: spark/presto.
	EngineType pulumi.StringOutput `pulumi:"engineType"`
	// Cluster image version name. Such as SuperSQL-P 1.1; SuperSQL-S 3.2, etc., do not upload, and create a cluster with the latest mirror version by default.
	ImageVersionName pulumi.StringOutput `pulumi:"imageVersionName"`
	// Primary cluster name, specified when creating a disaster recovery cluster.
	MainClusterName pulumi.StringPtrOutput `pulumi:"mainClusterName"`
	// Engine max cluster size, MaxClusters less than or equal to 10 and MaxClusters bigger than MinClusters.
	MaxClusters pulumi.IntPtrOutput `pulumi:"maxClusters"`
	// Maximum number of concurrent tasks in a single cluster, default 5.
	MaxConcurrency pulumi.IntOutput `pulumi:"maxConcurrency"`
	// Engine description information.
	Message pulumi.StringPtrOutput `pulumi:"message"`
	// Engine min size, greater than or equal to 1 and MaxClusters bigger than MinClusters.
	MinClusters pulumi.IntPtrOutput `pulumi:"minClusters"`
	// Engine mode, only support 1: ByAmount, 2: YearlyAndMonthly.
	Mode pulumi.IntOutput `pulumi:"mode"`
	// Engine pay mode type, only support 0: postPay, 1: prePay(default).
	PayMode pulumi.IntPtrOutput `pulumi:"payMode"`
	// Engine resource type not match, only support: Standard_CU/Memory_CU(only BATCH ExecType).
	ResourceType pulumi.StringOutput `pulumi:"resourceType"`
	// For spark Batch ExecType, cluster session resource configuration template.
	SessionResourceTemplate DataEngineSessionResourceTemplateOutput `pulumi:"sessionResourceTemplate"`
	// Cluster size. Required when updating.
	Size pulumi.IntPtrOutput `pulumi:"size"`
	// Engine TimeSpan, prePay: minimum of 1, representing one month of purchasing resources, with a maximum of 120, default 3600, postPay: fixed fee of 3600.
	TimeSpan pulumi.IntPtrOutput `pulumi:"timeSpan"`
	// Engine TimeUnit, prePay: use m(default), postPay: use h.
	TimeUnit pulumi.StringPtrOutput `pulumi:"timeUnit"`
	// Tolerable queuing time, default 0. scaling may be triggered when tasks are queued for longer than the tolerable time. if this parameter is 0, it means that capacity expansion may be triggered immediately once a task is queued.
	TolerableQueueTime pulumi.IntPtrOutput `pulumi:"tolerableQueueTime"`
}

// NewDataEngine registers a new resource with the given unique name, arguments, and options.
func NewDataEngine(ctx *pulumi.Context,
	name string, args *DataEngineArgs, opts ...pulumi.ResourceOption) (*DataEngine, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.AutoResume == nil {
		return nil, errors.New("invalid value for required argument 'AutoResume'")
	}
	if args.ClusterType == nil {
		return nil, errors.New("invalid value for required argument 'ClusterType'")
	}
	if args.DataEngineName == nil {
		return nil, errors.New("invalid value for required argument 'DataEngineName'")
	}
	if args.EngineType == nil {
		return nil, errors.New("invalid value for required argument 'EngineType'")
	}
	if args.Mode == nil {
		return nil, errors.New("invalid value for required argument 'Mode'")
	}
	opts = pkgResourceDefaultOpts(opts)
	var resource DataEngine
	err := ctx.RegisterResource("tencentcloud:Dlc/dataEngine:DataEngine", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetDataEngine gets an existing DataEngine resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetDataEngine(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *DataEngineState, opts ...pulumi.ResourceOption) (*DataEngine, error) {
	var resource DataEngine
	err := ctx.ReadResource("tencentcloud:Dlc/dataEngine:DataEngine", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering DataEngine resources.
type dataEngineState struct {
	// Engine auto renew, only support 0: Default, 1: AutoRenewON, 2: AutoRenewOFF.
	AutoRenew *int `pulumi:"autoRenew"`
	// Whether to automatically start the cluster, prepay not support.
	AutoResume *bool `pulumi:"autoResume"`
	// Whether to automatically suspend the cluster, prepay not support.
	AutoSuspend *bool `pulumi:"autoSuspend"`
	// Cluster automatic suspension time, default 10 minutes.
	AutoSuspendTime *int `pulumi:"autoSuspendTime"`
	// Engine VPC network segment, just like 192.0.2.1/24.
	CidrBlock *string `pulumi:"cidrBlock"`
	// Engine cluster type, only support: spark_cu/presto_cu.
	ClusterType *string `pulumi:"clusterType"`
	// Engine crontab resume or suspend strategy, only support: 0: Wait(default), 1: Kill.
	CrontabResumeSuspend *int `pulumi:"crontabResumeSuspend"`
	// Engine auto suspend strategy, when AutoSuspend is true, CrontabResumeSuspend must stop.
	CrontabResumeSuspendStrategy *DataEngineCrontabResumeSuspendStrategy `pulumi:"crontabResumeSuspendStrategy"`
	// Cluster advanced configuration.
	DataEngineConfigPairs []DataEngineDataEngineConfigPair `pulumi:"dataEngineConfigPairs"`
	// Engine name.
	DataEngineName *string `pulumi:"dataEngineName"`
	// Whether it is the default virtual cluster.
	DefaultDataEngine *bool `pulumi:"defaultDataEngine"`
	// For spark Batch ExecType, yearly and monthly cluster elastic limit.
	ElasticLimit *int `pulumi:"elasticLimit"`
	// For spark Batch ExecType, yearly and monthly cluster whether to enable elasticity.
	ElasticSwitch *bool `pulumi:"elasticSwitch"`
	// Engine exec type, only support SQL(default) or BATCH.
	EngineExecType *string `pulumi:"engineExecType"`
	// Engine type, only support: spark/presto.
	EngineType *string `pulumi:"engineType"`
	// Cluster image version name. Such as SuperSQL-P 1.1; SuperSQL-S 3.2, etc., do not upload, and create a cluster with the latest mirror version by default.
	ImageVersionName *string `pulumi:"imageVersionName"`
	// Primary cluster name, specified when creating a disaster recovery cluster.
	MainClusterName *string `pulumi:"mainClusterName"`
	// Engine max cluster size, MaxClusters less than or equal to 10 and MaxClusters bigger than MinClusters.
	MaxClusters *int `pulumi:"maxClusters"`
	// Maximum number of concurrent tasks in a single cluster, default 5.
	MaxConcurrency *int `pulumi:"maxConcurrency"`
	// Engine description information.
	Message *string `pulumi:"message"`
	// Engine min size, greater than or equal to 1 and MaxClusters bigger than MinClusters.
	MinClusters *int `pulumi:"minClusters"`
	// Engine mode, only support 1: ByAmount, 2: YearlyAndMonthly.
	Mode *int `pulumi:"mode"`
	// Engine pay mode type, only support 0: postPay, 1: prePay(default).
	PayMode *int `pulumi:"payMode"`
	// Engine resource type not match, only support: Standard_CU/Memory_CU(only BATCH ExecType).
	ResourceType *string `pulumi:"resourceType"`
	// For spark Batch ExecType, cluster session resource configuration template.
	SessionResourceTemplate *DataEngineSessionResourceTemplate `pulumi:"sessionResourceTemplate"`
	// Cluster size. Required when updating.
	Size *int `pulumi:"size"`
	// Engine TimeSpan, prePay: minimum of 1, representing one month of purchasing resources, with a maximum of 120, default 3600, postPay: fixed fee of 3600.
	TimeSpan *int `pulumi:"timeSpan"`
	// Engine TimeUnit, prePay: use m(default), postPay: use h.
	TimeUnit *string `pulumi:"timeUnit"`
	// Tolerable queuing time, default 0. scaling may be triggered when tasks are queued for longer than the tolerable time. if this parameter is 0, it means that capacity expansion may be triggered immediately once a task is queued.
	TolerableQueueTime *int `pulumi:"tolerableQueueTime"`
}

type DataEngineState struct {
	// Engine auto renew, only support 0: Default, 1: AutoRenewON, 2: AutoRenewOFF.
	AutoRenew pulumi.IntPtrInput
	// Whether to automatically start the cluster, prepay not support.
	AutoResume pulumi.BoolPtrInput
	// Whether to automatically suspend the cluster, prepay not support.
	AutoSuspend pulumi.BoolPtrInput
	// Cluster automatic suspension time, default 10 minutes.
	AutoSuspendTime pulumi.IntPtrInput
	// Engine VPC network segment, just like 192.0.2.1/24.
	CidrBlock pulumi.StringPtrInput
	// Engine cluster type, only support: spark_cu/presto_cu.
	ClusterType pulumi.StringPtrInput
	// Engine crontab resume or suspend strategy, only support: 0: Wait(default), 1: Kill.
	CrontabResumeSuspend pulumi.IntPtrInput
	// Engine auto suspend strategy, when AutoSuspend is true, CrontabResumeSuspend must stop.
	CrontabResumeSuspendStrategy DataEngineCrontabResumeSuspendStrategyPtrInput
	// Cluster advanced configuration.
	DataEngineConfigPairs DataEngineDataEngineConfigPairArrayInput
	// Engine name.
	DataEngineName pulumi.StringPtrInput
	// Whether it is the default virtual cluster.
	DefaultDataEngine pulumi.BoolPtrInput
	// For spark Batch ExecType, yearly and monthly cluster elastic limit.
	ElasticLimit pulumi.IntPtrInput
	// For spark Batch ExecType, yearly and monthly cluster whether to enable elasticity.
	ElasticSwitch pulumi.BoolPtrInput
	// Engine exec type, only support SQL(default) or BATCH.
	EngineExecType pulumi.StringPtrInput
	// Engine type, only support: spark/presto.
	EngineType pulumi.StringPtrInput
	// Cluster image version name. Such as SuperSQL-P 1.1; SuperSQL-S 3.2, etc., do not upload, and create a cluster with the latest mirror version by default.
	ImageVersionName pulumi.StringPtrInput
	// Primary cluster name, specified when creating a disaster recovery cluster.
	MainClusterName pulumi.StringPtrInput
	// Engine max cluster size, MaxClusters less than or equal to 10 and MaxClusters bigger than MinClusters.
	MaxClusters pulumi.IntPtrInput
	// Maximum number of concurrent tasks in a single cluster, default 5.
	MaxConcurrency pulumi.IntPtrInput
	// Engine description information.
	Message pulumi.StringPtrInput
	// Engine min size, greater than or equal to 1 and MaxClusters bigger than MinClusters.
	MinClusters pulumi.IntPtrInput
	// Engine mode, only support 1: ByAmount, 2: YearlyAndMonthly.
	Mode pulumi.IntPtrInput
	// Engine pay mode type, only support 0: postPay, 1: prePay(default).
	PayMode pulumi.IntPtrInput
	// Engine resource type not match, only support: Standard_CU/Memory_CU(only BATCH ExecType).
	ResourceType pulumi.StringPtrInput
	// For spark Batch ExecType, cluster session resource configuration template.
	SessionResourceTemplate DataEngineSessionResourceTemplatePtrInput
	// Cluster size. Required when updating.
	Size pulumi.IntPtrInput
	// Engine TimeSpan, prePay: minimum of 1, representing one month of purchasing resources, with a maximum of 120, default 3600, postPay: fixed fee of 3600.
	TimeSpan pulumi.IntPtrInput
	// Engine TimeUnit, prePay: use m(default), postPay: use h.
	TimeUnit pulumi.StringPtrInput
	// Tolerable queuing time, default 0. scaling may be triggered when tasks are queued for longer than the tolerable time. if this parameter is 0, it means that capacity expansion may be triggered immediately once a task is queued.
	TolerableQueueTime pulumi.IntPtrInput
}

func (DataEngineState) ElementType() reflect.Type {
	return reflect.TypeOf((*dataEngineState)(nil)).Elem()
}

type dataEngineArgs struct {
	// Engine auto renew, only support 0: Default, 1: AutoRenewON, 2: AutoRenewOFF.
	AutoRenew *int `pulumi:"autoRenew"`
	// Whether to automatically start the cluster, prepay not support.
	AutoResume bool `pulumi:"autoResume"`
	// Whether to automatically suspend the cluster, prepay not support.
	AutoSuspend *bool `pulumi:"autoSuspend"`
	// Cluster automatic suspension time, default 10 minutes.
	AutoSuspendTime *int `pulumi:"autoSuspendTime"`
	// Engine VPC network segment, just like 192.0.2.1/24.
	CidrBlock *string `pulumi:"cidrBlock"`
	// Engine cluster type, only support: spark_cu/presto_cu.
	ClusterType string `pulumi:"clusterType"`
	// Engine crontab resume or suspend strategy, only support: 0: Wait(default), 1: Kill.
	CrontabResumeSuspend *int `pulumi:"crontabResumeSuspend"`
	// Engine auto suspend strategy, when AutoSuspend is true, CrontabResumeSuspend must stop.
	CrontabResumeSuspendStrategy *DataEngineCrontabResumeSuspendStrategy `pulumi:"crontabResumeSuspendStrategy"`
	// Cluster advanced configuration.
	DataEngineConfigPairs []DataEngineDataEngineConfigPair `pulumi:"dataEngineConfigPairs"`
	// Engine name.
	DataEngineName string `pulumi:"dataEngineName"`
	// Whether it is the default virtual cluster.
	DefaultDataEngine *bool `pulumi:"defaultDataEngine"`
	// For spark Batch ExecType, yearly and monthly cluster elastic limit.
	ElasticLimit *int `pulumi:"elasticLimit"`
	// For spark Batch ExecType, yearly and monthly cluster whether to enable elasticity.
	ElasticSwitch *bool `pulumi:"elasticSwitch"`
	// Engine exec type, only support SQL(default) or BATCH.
	EngineExecType *string `pulumi:"engineExecType"`
	// Engine type, only support: spark/presto.
	EngineType string `pulumi:"engineType"`
	// Cluster image version name. Such as SuperSQL-P 1.1; SuperSQL-S 3.2, etc., do not upload, and create a cluster with the latest mirror version by default.
	ImageVersionName *string `pulumi:"imageVersionName"`
	// Primary cluster name, specified when creating a disaster recovery cluster.
	MainClusterName *string `pulumi:"mainClusterName"`
	// Engine max cluster size, MaxClusters less than or equal to 10 and MaxClusters bigger than MinClusters.
	MaxClusters *int `pulumi:"maxClusters"`
	// Maximum number of concurrent tasks in a single cluster, default 5.
	MaxConcurrency *int `pulumi:"maxConcurrency"`
	// Engine description information.
	Message *string `pulumi:"message"`
	// Engine min size, greater than or equal to 1 and MaxClusters bigger than MinClusters.
	MinClusters *int `pulumi:"minClusters"`
	// Engine mode, only support 1: ByAmount, 2: YearlyAndMonthly.
	Mode int `pulumi:"mode"`
	// Engine pay mode type, only support 0: postPay, 1: prePay(default).
	PayMode *int `pulumi:"payMode"`
	// Engine resource type not match, only support: Standard_CU/Memory_CU(only BATCH ExecType).
	ResourceType *string `pulumi:"resourceType"`
	// For spark Batch ExecType, cluster session resource configuration template.
	SessionResourceTemplate *DataEngineSessionResourceTemplate `pulumi:"sessionResourceTemplate"`
	// Cluster size. Required when updating.
	Size *int `pulumi:"size"`
	// Engine TimeSpan, prePay: minimum of 1, representing one month of purchasing resources, with a maximum of 120, default 3600, postPay: fixed fee of 3600.
	TimeSpan *int `pulumi:"timeSpan"`
	// Engine TimeUnit, prePay: use m(default), postPay: use h.
	TimeUnit *string `pulumi:"timeUnit"`
	// Tolerable queuing time, default 0. scaling may be triggered when tasks are queued for longer than the tolerable time. if this parameter is 0, it means that capacity expansion may be triggered immediately once a task is queued.
	TolerableQueueTime *int `pulumi:"tolerableQueueTime"`
}

// The set of arguments for constructing a DataEngine resource.
type DataEngineArgs struct {
	// Engine auto renew, only support 0: Default, 1: AutoRenewON, 2: AutoRenewOFF.
	AutoRenew pulumi.IntPtrInput
	// Whether to automatically start the cluster, prepay not support.
	AutoResume pulumi.BoolInput
	// Whether to automatically suspend the cluster, prepay not support.
	AutoSuspend pulumi.BoolPtrInput
	// Cluster automatic suspension time, default 10 minutes.
	AutoSuspendTime pulumi.IntPtrInput
	// Engine VPC network segment, just like 192.0.2.1/24.
	CidrBlock pulumi.StringPtrInput
	// Engine cluster type, only support: spark_cu/presto_cu.
	ClusterType pulumi.StringInput
	// Engine crontab resume or suspend strategy, only support: 0: Wait(default), 1: Kill.
	CrontabResumeSuspend pulumi.IntPtrInput
	// Engine auto suspend strategy, when AutoSuspend is true, CrontabResumeSuspend must stop.
	CrontabResumeSuspendStrategy DataEngineCrontabResumeSuspendStrategyPtrInput
	// Cluster advanced configuration.
	DataEngineConfigPairs DataEngineDataEngineConfigPairArrayInput
	// Engine name.
	DataEngineName pulumi.StringInput
	// Whether it is the default virtual cluster.
	DefaultDataEngine pulumi.BoolPtrInput
	// For spark Batch ExecType, yearly and monthly cluster elastic limit.
	ElasticLimit pulumi.IntPtrInput
	// For spark Batch ExecType, yearly and monthly cluster whether to enable elasticity.
	ElasticSwitch pulumi.BoolPtrInput
	// Engine exec type, only support SQL(default) or BATCH.
	EngineExecType pulumi.StringPtrInput
	// Engine type, only support: spark/presto.
	EngineType pulumi.StringInput
	// Cluster image version name. Such as SuperSQL-P 1.1; SuperSQL-S 3.2, etc., do not upload, and create a cluster with the latest mirror version by default.
	ImageVersionName pulumi.StringPtrInput
	// Primary cluster name, specified when creating a disaster recovery cluster.
	MainClusterName pulumi.StringPtrInput
	// Engine max cluster size, MaxClusters less than or equal to 10 and MaxClusters bigger than MinClusters.
	MaxClusters pulumi.IntPtrInput
	// Maximum number of concurrent tasks in a single cluster, default 5.
	MaxConcurrency pulumi.IntPtrInput
	// Engine description information.
	Message pulumi.StringPtrInput
	// Engine min size, greater than or equal to 1 and MaxClusters bigger than MinClusters.
	MinClusters pulumi.IntPtrInput
	// Engine mode, only support 1: ByAmount, 2: YearlyAndMonthly.
	Mode pulumi.IntInput
	// Engine pay mode type, only support 0: postPay, 1: prePay(default).
	PayMode pulumi.IntPtrInput
	// Engine resource type not match, only support: Standard_CU/Memory_CU(only BATCH ExecType).
	ResourceType pulumi.StringPtrInput
	// For spark Batch ExecType, cluster session resource configuration template.
	SessionResourceTemplate DataEngineSessionResourceTemplatePtrInput
	// Cluster size. Required when updating.
	Size pulumi.IntPtrInput
	// Engine TimeSpan, prePay: minimum of 1, representing one month of purchasing resources, with a maximum of 120, default 3600, postPay: fixed fee of 3600.
	TimeSpan pulumi.IntPtrInput
	// Engine TimeUnit, prePay: use m(default), postPay: use h.
	TimeUnit pulumi.StringPtrInput
	// Tolerable queuing time, default 0. scaling may be triggered when tasks are queued for longer than the tolerable time. if this parameter is 0, it means that capacity expansion may be triggered immediately once a task is queued.
	TolerableQueueTime pulumi.IntPtrInput
}

func (DataEngineArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*dataEngineArgs)(nil)).Elem()
}

type DataEngineInput interface {
	pulumi.Input

	ToDataEngineOutput() DataEngineOutput
	ToDataEngineOutputWithContext(ctx context.Context) DataEngineOutput
}

func (*DataEngine) ElementType() reflect.Type {
	return reflect.TypeOf((**DataEngine)(nil)).Elem()
}

func (i *DataEngine) ToDataEngineOutput() DataEngineOutput {
	return i.ToDataEngineOutputWithContext(context.Background())
}

func (i *DataEngine) ToDataEngineOutputWithContext(ctx context.Context) DataEngineOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DataEngineOutput)
}

// DataEngineArrayInput is an input type that accepts DataEngineArray and DataEngineArrayOutput values.
// You can construct a concrete instance of `DataEngineArrayInput` via:
//
//	DataEngineArray{ DataEngineArgs{...} }
type DataEngineArrayInput interface {
	pulumi.Input

	ToDataEngineArrayOutput() DataEngineArrayOutput
	ToDataEngineArrayOutputWithContext(context.Context) DataEngineArrayOutput
}

type DataEngineArray []DataEngineInput

func (DataEngineArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*DataEngine)(nil)).Elem()
}

func (i DataEngineArray) ToDataEngineArrayOutput() DataEngineArrayOutput {
	return i.ToDataEngineArrayOutputWithContext(context.Background())
}

func (i DataEngineArray) ToDataEngineArrayOutputWithContext(ctx context.Context) DataEngineArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DataEngineArrayOutput)
}

// DataEngineMapInput is an input type that accepts DataEngineMap and DataEngineMapOutput values.
// You can construct a concrete instance of `DataEngineMapInput` via:
//
//	DataEngineMap{ "key": DataEngineArgs{...} }
type DataEngineMapInput interface {
	pulumi.Input

	ToDataEngineMapOutput() DataEngineMapOutput
	ToDataEngineMapOutputWithContext(context.Context) DataEngineMapOutput
}

type DataEngineMap map[string]DataEngineInput

func (DataEngineMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*DataEngine)(nil)).Elem()
}

func (i DataEngineMap) ToDataEngineMapOutput() DataEngineMapOutput {
	return i.ToDataEngineMapOutputWithContext(context.Background())
}

func (i DataEngineMap) ToDataEngineMapOutputWithContext(ctx context.Context) DataEngineMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(DataEngineMapOutput)
}

type DataEngineOutput struct{ *pulumi.OutputState }

func (DataEngineOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**DataEngine)(nil)).Elem()
}

func (o DataEngineOutput) ToDataEngineOutput() DataEngineOutput {
	return o
}

func (o DataEngineOutput) ToDataEngineOutputWithContext(ctx context.Context) DataEngineOutput {
	return o
}

// Engine auto renew, only support 0: Default, 1: AutoRenewON, 2: AutoRenewOFF.
func (o DataEngineOutput) AutoRenew() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.AutoRenew }).(pulumi.IntPtrOutput)
}

// Whether to automatically start the cluster, prepay not support.
func (o DataEngineOutput) AutoResume() pulumi.BoolOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.BoolOutput { return v.AutoResume }).(pulumi.BoolOutput)
}

// Whether to automatically suspend the cluster, prepay not support.
func (o DataEngineOutput) AutoSuspend() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.BoolPtrOutput { return v.AutoSuspend }).(pulumi.BoolPtrOutput)
}

// Cluster automatic suspension time, default 10 minutes.
func (o DataEngineOutput) AutoSuspendTime() pulumi.IntOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntOutput { return v.AutoSuspendTime }).(pulumi.IntOutput)
}

// Engine VPC network segment, just like 192.0.2.1/24.
func (o DataEngineOutput) CidrBlock() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringPtrOutput { return v.CidrBlock }).(pulumi.StringPtrOutput)
}

// Engine cluster type, only support: spark_cu/presto_cu.
func (o DataEngineOutput) ClusterType() pulumi.StringOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringOutput { return v.ClusterType }).(pulumi.StringOutput)
}

// Engine crontab resume or suspend strategy, only support: 0: Wait(default), 1: Kill.
func (o DataEngineOutput) CrontabResumeSuspend() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.CrontabResumeSuspend }).(pulumi.IntPtrOutput)
}

// Engine auto suspend strategy, when AutoSuspend is true, CrontabResumeSuspend must stop.
func (o DataEngineOutput) CrontabResumeSuspendStrategy() DataEngineCrontabResumeSuspendStrategyOutput {
	return o.ApplyT(func(v *DataEngine) DataEngineCrontabResumeSuspendStrategyOutput {
		return v.CrontabResumeSuspendStrategy
	}).(DataEngineCrontabResumeSuspendStrategyOutput)
}

// Cluster advanced configuration.
func (o DataEngineOutput) DataEngineConfigPairs() DataEngineDataEngineConfigPairArrayOutput {
	return o.ApplyT(func(v *DataEngine) DataEngineDataEngineConfigPairArrayOutput { return v.DataEngineConfigPairs }).(DataEngineDataEngineConfigPairArrayOutput)
}

// Engine name.
func (o DataEngineOutput) DataEngineName() pulumi.StringOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringOutput { return v.DataEngineName }).(pulumi.StringOutput)
}

// Whether it is the default virtual cluster.
func (o DataEngineOutput) DefaultDataEngine() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.BoolPtrOutput { return v.DefaultDataEngine }).(pulumi.BoolPtrOutput)
}

// For spark Batch ExecType, yearly and monthly cluster elastic limit.
func (o DataEngineOutput) ElasticLimit() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.ElasticLimit }).(pulumi.IntPtrOutput)
}

// For spark Batch ExecType, yearly and monthly cluster whether to enable elasticity.
func (o DataEngineOutput) ElasticSwitch() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.BoolPtrOutput { return v.ElasticSwitch }).(pulumi.BoolPtrOutput)
}

// Engine exec type, only support SQL(default) or BATCH.
func (o DataEngineOutput) EngineExecType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringPtrOutput { return v.EngineExecType }).(pulumi.StringPtrOutput)
}

// Engine type, only support: spark/presto.
func (o DataEngineOutput) EngineType() pulumi.StringOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringOutput { return v.EngineType }).(pulumi.StringOutput)
}

// Cluster image version name. Such as SuperSQL-P 1.1; SuperSQL-S 3.2, etc., do not upload, and create a cluster with the latest mirror version by default.
func (o DataEngineOutput) ImageVersionName() pulumi.StringOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringOutput { return v.ImageVersionName }).(pulumi.StringOutput)
}

// Primary cluster name, specified when creating a disaster recovery cluster.
func (o DataEngineOutput) MainClusterName() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringPtrOutput { return v.MainClusterName }).(pulumi.StringPtrOutput)
}

// Engine max cluster size, MaxClusters less than or equal to 10 and MaxClusters bigger than MinClusters.
func (o DataEngineOutput) MaxClusters() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.MaxClusters }).(pulumi.IntPtrOutput)
}

// Maximum number of concurrent tasks in a single cluster, default 5.
func (o DataEngineOutput) MaxConcurrency() pulumi.IntOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntOutput { return v.MaxConcurrency }).(pulumi.IntOutput)
}

// Engine description information.
func (o DataEngineOutput) Message() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringPtrOutput { return v.Message }).(pulumi.StringPtrOutput)
}

// Engine min size, greater than or equal to 1 and MaxClusters bigger than MinClusters.
func (o DataEngineOutput) MinClusters() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.MinClusters }).(pulumi.IntPtrOutput)
}

// Engine mode, only support 1: ByAmount, 2: YearlyAndMonthly.
func (o DataEngineOutput) Mode() pulumi.IntOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntOutput { return v.Mode }).(pulumi.IntOutput)
}

// Engine pay mode type, only support 0: postPay, 1: prePay(default).
func (o DataEngineOutput) PayMode() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.PayMode }).(pulumi.IntPtrOutput)
}

// Engine resource type not match, only support: Standard_CU/Memory_CU(only BATCH ExecType).
func (o DataEngineOutput) ResourceType() pulumi.StringOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringOutput { return v.ResourceType }).(pulumi.StringOutput)
}

// For spark Batch ExecType, cluster session resource configuration template.
func (o DataEngineOutput) SessionResourceTemplate() DataEngineSessionResourceTemplateOutput {
	return o.ApplyT(func(v *DataEngine) DataEngineSessionResourceTemplateOutput { return v.SessionResourceTemplate }).(DataEngineSessionResourceTemplateOutput)
}

// Cluster size. Required when updating.
func (o DataEngineOutput) Size() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.Size }).(pulumi.IntPtrOutput)
}

// Engine TimeSpan, prePay: minimum of 1, representing one month of purchasing resources, with a maximum of 120, default 3600, postPay: fixed fee of 3600.
func (o DataEngineOutput) TimeSpan() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.TimeSpan }).(pulumi.IntPtrOutput)
}

// Engine TimeUnit, prePay: use m(default), postPay: use h.
func (o DataEngineOutput) TimeUnit() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.StringPtrOutput { return v.TimeUnit }).(pulumi.StringPtrOutput)
}

// Tolerable queuing time, default 0. scaling may be triggered when tasks are queued for longer than the tolerable time. if this parameter is 0, it means that capacity expansion may be triggered immediately once a task is queued.
func (o DataEngineOutput) TolerableQueueTime() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *DataEngine) pulumi.IntPtrOutput { return v.TolerableQueueTime }).(pulumi.IntPtrOutput)
}

type DataEngineArrayOutput struct{ *pulumi.OutputState }

func (DataEngineArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*DataEngine)(nil)).Elem()
}

func (o DataEngineArrayOutput) ToDataEngineArrayOutput() DataEngineArrayOutput {
	return o
}

func (o DataEngineArrayOutput) ToDataEngineArrayOutputWithContext(ctx context.Context) DataEngineArrayOutput {
	return o
}

func (o DataEngineArrayOutput) Index(i pulumi.IntInput) DataEngineOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *DataEngine {
		return vs[0].([]*DataEngine)[vs[1].(int)]
	}).(DataEngineOutput)
}

type DataEngineMapOutput struct{ *pulumi.OutputState }

func (DataEngineMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*DataEngine)(nil)).Elem()
}

func (o DataEngineMapOutput) ToDataEngineMapOutput() DataEngineMapOutput {
	return o
}

func (o DataEngineMapOutput) ToDataEngineMapOutputWithContext(ctx context.Context) DataEngineMapOutput {
	return o
}

func (o DataEngineMapOutput) MapIndex(k pulumi.StringInput) DataEngineOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *DataEngine {
		return vs[0].(map[string]*DataEngine)[vs[1].(string)]
	}).(DataEngineOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*DataEngineInput)(nil)).Elem(), &DataEngine{})
	pulumi.RegisterInputType(reflect.TypeOf((*DataEngineArrayInput)(nil)).Elem(), DataEngineArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*DataEngineMapInput)(nil)).Elem(), DataEngineMap{})
	pulumi.RegisterOutputType(DataEngineOutput{})
	pulumi.RegisterOutputType(DataEngineArrayOutput{})
	pulumi.RegisterOutputType(DataEngineMapOutput{})
}
